# Rook Ceph

## Install ROOK CEPH from Controller-0
```
cd ~
git clone --single-branch --branch v1.7.2 https://github.com/rook/rook.git
cd rook/cluster/examples/kubernetes/ceph/
```

## Deploy the Rook Operator
```
kubectl create -f crds.yaml -f common.yaml -f operator.yaml
```

## Create a Ceph Cluster
```
kubectl create -f cluster.yaml
```

## Wait until all pods running
```
kubectl get pods -n rook-ceph --watch
ctrl + c

kubectl get pods -n rook-ceph
```

## Deploy Rook Ceph toolbox
## The Rook Ceph toolbox is a container with common tools used for rook debugging and testing.
```
cd ~
cd rook/cluster/examples/kubernetes/ceph
kubectl apply -f toolbox.yaml
```

## Viewing the Dashboard External to the Cluster
## Node Port

The simplest way to expose the service is using the NodePort to open a port on the VM that can be accessed by the host. To create a service with the NodePort.
Now create the service:
```
kubectl create -f dashboard-external-https.yaml
```

You will see the new service rook-ceph-mgr-dashboard-external-https created:
```
kubectl -n rook-ceph get service
```

Once the rook-ceph-tools pod is running, you can connect to it with:
```
kubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- bash
```
All available tools in the toolbox are ready for your troubleshooting needs.
Example:
```
ceph status
```

```
ceph osd status
```

```
ceph df
```

```
rados df
```

## Exit to controller-0
```
exit
```

## Login Credentials
After you connect to the dashboard you will need to login for secure access. Rook creates a default user named admin and generates a secret called rook-ceph-dashboard-password in the namespace where the Rook Ceph cluster is running. To retrieve the generated password, you can run the following:
```
kubectl -n rook-ceph get secret rook-ceph-dashboard-password -o jsonpath="{['data']['password']}" | base64 --decode && echo
|E./aK"D04oR7TXB`ZMJ
```

## Create firewall-rule for ROOK CEPH web dashboard
```
NODE_PORT=$(kubectl -n rook-ceph get svc rook-ceph-mgr-dashboard-external-https \
  --output=jsonpath='{range .spec.ports[0]}{.nodePort}')

echo $NODE_PORT
32347

exit
```

## Create firewall rule for ROOK CEPH dashboard
this is for simulation purpose, not recommended using this, other option available
```
aws ec2 authorize-security-group-ingress \
  --group-id ${SECURITY_GROUP_ID} \
  --protocol tcp \
  --port 32347 \
  --cidr 0.0.0.0/0
```

## Get worker-0 external ip
```
aws ec2 describe-instances \
  --filters Name=vpc-id,Values=${VPC_ID} \
  --query 'sort_by(Reservations[].Instances[],&PrivateIpAddress)[].{d_INTERNAL_IP:PrivateIpAddress,e_EXTERNAL_IP:PublicIpAddress,a_NAME:Tags[?Key==`Name`].Value | [0],b_ZONE:Placement.AvailabilityZone,c_MACHINE_TYPE:InstanceType,f_STATUS:State.Name}' \
  --output table
54.225.38.106
```

## Generate ceph dashboard url and login using user admin and password from login credential
```
https://54.225.38.106:32347
```

## SSH to controller-0 Nodes
```
external_ip=$(aws ec2 describe-instances \
  --filters "Name=tag:Name,Values=controller-0" "Name=instance-state-name,Values=running" \
  --output text --query 'Reservations[].Instances[].PublicIpAddress')
ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
  -i example-k8s.id_rsa ubuntu@${external_ip}
```

## Create pool shared filesystem in CEPH (cephfs)
```
cd ~
cd rook/cluster/examples/kubernetes/ceph/
kubectl create -f filesystem.yaml
```

## Create storage class for cephfs
```
kubectl create -f csi/cephfs/storageclass.yaml
kubectl get sc
```


Next: [Part 10 - Getting access to Rancher](11-part-10.md)
